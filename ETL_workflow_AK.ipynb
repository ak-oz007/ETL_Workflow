{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to a file\n",
    "logging.basicConfig(filename='etl_process.log', level=logging.INFO, format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract data from CSV files\n",
    "def extract_csv(file_path):\n",
    "    logging.info(f\"Extracting CSV file: {file_path}\")\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract data from JSON files\n",
    "def extract_json(file_path):\n",
    "    logging.info(f\"Extracting JSON file: {file_path}\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract data from XML files\n",
    "def extract_xml(file_path):\n",
    "    logging.info(f\"Extracting XML file: {file_path}\")\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    rows = []\n",
    "    for child in root:\n",
    "        row = {}\n",
    "        for element in child:\n",
    "            #storing the element tag and the text in dict row \n",
    "            row[element.tag] = element.text\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract the data from different formats and combining it to a single dataframe\n",
    "def extract_data(directory):\n",
    "    logging.info(\"Starting extraction phase\")\n",
    "    dfs = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if file_name.endswith('.csv'):\n",
    "            dfs.append(extract_csv(file_path))\n",
    "        elif file_name.endswith('.json'):\n",
    "            dfs.append(extract_json(file_path))\n",
    "        elif file_name.endswith('.xml'):\n",
    "            dfs.append(extract_xml(file_path))\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    logging.info(\"Extraction phase completed\")\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to transform the height in inches to meters and weight in pounds to kgs\n",
    "def transform_data(df):\n",
    "    logging.info(\"Starting transformation phase\")\n",
    "    df = df.astype({\"name\":'object', \"height\":'float64', \"weight\":'float64'})\n",
    "    df['height'] = df['height'].apply(lambda x: x * 0.0254 if x > 0 else x)  # Assuming heights are in inches\n",
    "    df['weight'] = df['weight'].apply(lambda x: x * 0.453592 if x > 0 else x)  # Assuming weights are in pounds\n",
    "    logging.info(\"Transformation phase completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the transformed data into csv file\n",
    "def load_data(df, output_file):\n",
    "    logging.info(\"Starting loading phase\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logging.info(\"Loading phase completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to execute ETL process\n",
    "def etl_process(input_directory, output_file):\n",
    "    logging.info(\"ETL process started\")\n",
    "    df = extract_data(input_directory)\n",
    "    df = transform_data(df)\n",
    "    load_data(df, output_file)\n",
    "    logging.info(\"ETL process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#Setting the directory path and output file to store the transformed data\n",
    "input_directory = r\"C:\\Users\\admin\\Data Eng Workspace\\Comprehensive_ETL_Workflow\"\n",
    "output_file = r\"C:\\Users\\admin\\Data Eng Workspace\\Comprehensive_ETL_Workflow\\Transformed_data\\Output_transformed.csv\"\n",
    "etl_process(input_directory,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
